import torch
from transformers import Qwen2_5OmniForConditionalGeneration, Qwen2_5OmniProcessor

model_dir = "/data/public/models/Qwen2.5-Omni-7B" 

print(f"ğŸ” ë¡œë”© ê²½ë¡œ í™•ì¸: {model_dir}")

try:
    model = Qwen2_5OmniForConditionalGeneration.from_pretrained(
        model_dir,
        torch_dtype=torch.bfloat16,
        device_map="auto",
        trust_remote_code=True
    )
    processor = Qwen2_5OmniProcessor.from_pretrained(
        model_dir,
        trust_remote_code=True
    )
    print("âœ… ëª¨ë¸ ë¡œë”© ì„±ê³µ")
    print(f"ğŸ“¦ model dtype: {model.dtype}")
    print(f"ğŸ“¦ model device map: {model.hf_device_map}")
except Exception as e:
    print("âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨:", e)
